<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="mbK83M8fq9oKpHxh7VGEx7oKdTj2XSyJ6unZ3MoB0Lk"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>recommended | Joren Brunekreef</title> <meta name="author" content="Joren Brunekreef"> <meta name="description" content="Stuff I find interesting"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A4%96&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jorenb.github.io/recommended/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Joren </span>Brunekreef</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item active"> <a class="nav-link" href="/recommended/">recommended<span class="sr-only">(current)</span></a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">recommended</h1> <p class="post-description">Stuff I find interesting</p> </header> <article> <div class="recommendations"> <h2 class="category">Statistics</h2> <ul class="rec-list"> <li> <h3><a href="https://lakens.github.io/statistical_inferences/" rel="external nofollow noopener" target="_blank">Improving Your Statistical Inferences</a></h3> <p class="post-authors"> by Daniël Lakens</p> <p class="post-description">Before reading this set of notes, I knew how to compute p-values and confidence intervals and I understood how to set up a Neyman-Pearson hypothesis test. However, I had only vague ideas of what these concepts exactly meant. Even worse, some of these ideas turned out to be flat wrong. Carefully reading the first seven sections of these notes helped me clear up a lot of confusion and ill-formed notions about statistical concepts. The "test yourself" questions at the end of each section are sufficiently difficult to check whether you grasped the main messages, and sufficiently simple so that you don't really have an excuse for skipping them. </p> </li> </ul> <h2 class="category">Physics</h2> <ul class="rec-list"> <li> <h3><a href="https://www.aip.org/history-programs/niels-bohr-library/oral-histories/46968" rel="external nofollow noopener" target="_blank">Oral Histories: Edward Witten</a></h3> <p class="post-authors"> by David Zierler</p> <p class="post-description"></p> </li> <li> <h3><a href="https://pos.sissa.it/406/316" rel="external nofollow noopener" target="_blank">Quantum Gravity in 30 Questions</a></h3> <p class="post-authors"> by Renate Loll, Giuseppe Fabiano, Domenico Frattulillo, and Fabian Wagner</p> <p class="post-description"></p> </li> </ul> <h2 class="category">Scientific Integrity</h2> <ul class="rec-list"> <li> <h3><a href="https://arxiv.org/abs/2207.07048" rel="external nofollow noopener" target="_blank">Leakage and the Reproducibility Crisis in ML-based Science</a></h3> <p class="post-authors"> by Sayash Kapoor and Arvind Narayanan</p> <p class="post-description"></p> </li> <li> <h3><a href="https://journals.sagepub.com/doi/10.1177/1745691620966795" rel="external nofollow noopener" target="_blank">Why Hypothesis Testers Should Spend Less Time Testing Hypotheses</a></h3> <p class="post-authors"> by Anne Scheel, Leonid Tiokhin, Peder Isager, and Daniël Lakens</p> <p class="post-description"></p> </li> </ul> <h2 class="category">Deep Learning</h2> <ul class="rec-list"> <li> <h3><a href="https://www.youtube.com/watch?v=zjkBMFhNj_g" rel="external nofollow noopener" target="_blank">Intro to Large Language Models</a></h3> <p class="post-authors"> by Andrej Karpathy</p> <p class="post-description">If you want to get a rough understanding of the way ChatGPT works, this video is a great starting point. An especially useful notion to internalize is that language models are essentially trained to 'dream' text, and that we nudge its dreams into useful answers through our prompts. It may also provide some intuition for why ChatGPTs basic reasoning capabilities are sometimes so surprisingly bad in comparison to how well it works for other tasks. </p> </li> <li> <h3><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY" rel="external nofollow noopener" target="_blank">Let's Build GPT: From Scratch, in Code, Spelled Out</a></h3> <p class="post-authors"> by Andrej Karpathy</p> <p class="post-description">The highly technical companion to the video above. I used to have a hard time trying to understand the Transformer architecture, even after reading some nice <a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" rel="external nofollow noopener" target="_blank">expository</a> <a href="https://jalammar.github.io/illustrated-transformer/" rel="external nofollow noopener" target="_blank">blog</a> <a href="https://www.columbia.edu/~jsl2239/transformers.html" rel="external nofollow noopener" target="_blank">posts</a>. In this video, you get to build a simple decoder-only Transformer from the ground up (that is, if you consider PyTorch as sea level), all the while seeing how the different elements in the setup contribute to a progressively better performance. I suggest to watch the entire thing from start to finish first at 1.5x speed, in order to get a general impression of where you're going. Then, restart from the beginning, and pause every now and then to type out (and run) the code yourself. Experiment with different hyperparameter values (e.g. for block size, batch size, embedding dimension, etc) to get a feel for the tradeoffs you have to deal with here. Another nice exercise is to change the tokenization so that the tokens are bigrams instead of single characters. </p> </li> <li> <h3><a href="https://github.com/tinygrad/tinygrad" rel="external nofollow noopener" target="_blank">tinygrad</a></h3> <p class="post-authors"> by tiny corp</p> <p class="post-description">A simple and lightweight autograd/tensor library for constructing deep learning models. Its syntax resembles PyTorch, although it's not completely identical. I found it instructive to redo the <a href="https://www.youtube.com/watch?v=kCc8FmEb1nY" rel="external nofollow noopener" target="_blank">GPT From Scratch tutorial</a>, swapping out PyTorch for tinygrad. One downside: it's under rapid development, so some features are not that stable — for example, the MPS backend was broken for some time on my MacOS version. The upside: it's under rapid development, so this issue was fixed within a few weeks. They also offer cash bounties for certain code contributions, so fixing open issues can put a little cash in your pocket in addition to being somewhat educational. </p> </li> <li> <h3><a href="http://bactra.org/notebooks/nn-attention-and-transformers.html" rel="external nofollow noopener" target="_blank">"Attention", "Transformers", in Neural Network "Large Language Models"</a></h3> <p class="post-authors"> by Cosma Shalizi</p> <p class="post-description">A no-nonsense investigation into the transformer architecture. The author is noticeably annoyed with the lack of precise and carefully worded discussions on transformers and self-attention, and he does a great job at partially fixing this without resorting to handwavy explanations. Also, he's brutally honest about the parts he still doesn't understand (like, <i>why</i> layer-norm?). Something that especially stuck with me: the dot-product attention matrix is essentially some kind of <a href="https://teazrq.github.io/SMLR/kernel-smoothing.html" rel="external nofollow noopener" target="_blank">kernel smoothing</a> in the embedding space. </p> </li> </ul> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Joren Brunekreef. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: August 14, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-NZXH5MQL6C"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-NZXH5MQL6C");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>